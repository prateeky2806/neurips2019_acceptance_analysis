{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter \n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://neurips.cc/Conferences/2019/AcceptedPapersInitial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = []\n",
    "authors = []    #paper and authors are index aligned.\n",
    "for tag in soup.find_all('p'):\n",
    "    if len(tag.find_all('i')) == 1 and len(tag.find_all('b')) == 1:\n",
    "        papers.append(tag.find_all('b')[0].contents[0])\n",
    "        authors.append(tag.find_all('i')[0].contents[0])\n",
    "\n",
    "split_char = authors[0][38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find all papers and authors containing a keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'influence'\n",
    "\n",
    "paper_key = []\n",
    "author_key = []\n",
    "indices = []\n",
    "for i, paper in enumerate(papers):\n",
    "    if keyword in paper.lower():\n",
    "        paper_key.append(paper)\n",
    "        for item in authors[i].split(split_char):\n",
    "            author_key.append(item.split('(')[0].strip().lower().replace(\" \", \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Disentangling Influence: Using disentangled representations to audit model predictions', 'On the Accuracy of Influence Functions for Measuring Group Effects', 'Adaptive Influence Maximization with Myopic Feedback']\n",
      "['charles_marx', 'richard_phillips', 'sorelle_friedler', 'carlos__scheidegger', 'suresh_venkatasubramanian', 'pang_wei_w_koh', 'kai-siang_ang', 'hubert_teo', 'percy_liang', 'binghui_peng', 'wei_chen']\n"
     ]
    }
   ],
   "source": [
    "print(paper_key)\n",
    "print(author_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain frequency of authors and top publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_list = []\n",
    "for author in authors:\n",
    "    for item in author.split(split_char):\n",
    "#         print(item)\n",
    "        author_list.append(item.split('(')[0].strip().lower().replace(\" \", \"_\"))\n",
    "\n",
    "author_freq = Counter(author_list)    #dictionary with authors as key and number of papers as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sergey_levine: 12\n",
      "francis_bach: 10\n",
      "pieter_abbeel: 9\n",
      "yoshua_bengio: 9\n",
      "ruslan_salakhutdinov: 9\n",
      "dacheng_tao: 8\n",
      "zhao_song: 7\n",
      "shimon_whiteson: 7\n",
      "david_woodruff: 7\n",
      "andreas_krause: 7\n",
      "zhuoran_yang: 7\n"
     ]
    }
   ],
   "source": [
    "k = 11    #top-k publishers will be displayed\n",
    "for tup in author_freq.most_common(k):\n",
    "    print('{}: {}'.format(tup[0],tup[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query publications and its count via author name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'Joan Bruna'\n",
    "author_freq.get(name.lower().replace(\" \", \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stability of Graph Scattering Transforms',\n",
       " 'Gradient Dynamics of Shallow Low-Dimensional ReLU Networks',\n",
       " 'Finding the Needle in the Haystack with Convolutions: on the benefits of architectural bias',\n",
       " 'On the Expressive Power of Deep Polynomial Neural Networks',\n",
       " 'On the equivalence between graph isomorphism testing and function approximation with GNNs']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_auth = []\n",
    "for i, author in enumerate(authors):\n",
    "    if name.lower() in author.lower():\n",
    "        paper_auth.append(papers[i])\n",
    "\n",
    "paper_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
